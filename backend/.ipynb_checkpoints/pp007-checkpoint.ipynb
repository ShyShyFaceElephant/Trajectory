{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb26b36-d369-49c3-8594-2e18c3cb5914",
   "metadata": {},
   "source": [
    "# 前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc20b1c6-84dc-4ed3-a264-32fd7b55a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "from antspynet.utilities import brain_extraction\n",
    "import ants\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "def ants_2_itk(image):\n",
    "    imageITK = sitk.GetImageFromArray(image.numpy().T)\n",
    "    imageITK.SetOrigin(image.origin)\n",
    "    imageITK.SetSpacing(image.spacing)\n",
    "    imageITK.SetDirection(image.direction.reshape(9))\n",
    "    return imageITK\n",
    "\n",
    "def itk_2_ants(image):\n",
    "    image_ants = ants.from_numpy(sitk.GetArrayFromImage(image).T, \n",
    "                                 origin=image.GetOrigin(), \n",
    "                                 spacing=image.GetSpacing(), \n",
    "                                 direction=np.array(image.GetDirection()).reshape(3, 3))\n",
    "    return image_ants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d162ab-b358-4664-93f4-7f4acf12a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### 去顱骨 #####################\n",
    "def ants_skull_stripping(input_image):\n",
    "    # 用 U-net 生成機率圖\n",
    "    prob_brain_mask = brain_extraction(input_image,modality='t1',verbose=False)\n",
    "    # 將機率圖轉換為遮罩\n",
    "    brain_mask = ants.get_mask(prob_brain_mask,low_thresh=0.5)\n",
    "    # 套用遮罩\n",
    "    masked_image = ants.mask_image(input_image,brain_mask)\n",
    "    # 輸出檔案\n",
    "    #masked_image.to_file(r'lab/IXI_brain_test.nii')\n",
    "    return masked_image\n",
    "##################### 去顱骨 #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382ab7df-ff68-4826-a235-9080fa6919e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### MNI配準 #####################\n",
    "def sitk_mni_registration(input_image,template_image):\n",
    "    # 宣告初始變換\n",
    "    initial_transform = sitk.CenteredTransformInitializer(\n",
    "        template_image,\n",
    "        input_image,\n",
    "        sitk.Euler3DTransform(),  # 使用剛體變換\n",
    "        sitk.CenteredTransformInitializerFilter.GEOMETRY\n",
    "    )\n",
    "    # 宣告配準方法\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "    \n",
    "    # 設定配準方法\n",
    "    # 初始變換\n",
    "    registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
    "    # 評估函數：Mattes Mutal Information\n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetMetricSamplingPercentage(0.01)\n",
    "    # 設定優化器：Gradient Descent\n",
    "    registration_method.SetOptimizerAsGradientDescent(learningRate=1.0, numberOfIterations=100, \n",
    "                                                      convergenceMinimumValue=1e-6, convergenceWindowSize=10)\n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift() #特別重要\n",
    "    # 設定插值方法：Linear\n",
    "    registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "    \n",
    "    # 執行配準\n",
    "    final_transform = registration_method.Execute(template_image, input_image)\n",
    "    # 套用配準\n",
    "    registered_image = sitk.Resample(input_image, template_image, final_transform, \n",
    "                                 sitk.sitkLinear, 0.0, input_image.GetPixelID())\n",
    "    # 輸出\n",
    "    return registered_image\n",
    "#################### MNI配準 #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad31a089-a5e8-4341-8382-cec630853578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(template_image,input_image,output_dir):\n",
    "    # 強度歸一 (result)\n",
    "    input_image = itk_2_ants(registered_image)\n",
    "    truncated_img = ants.iMath_truncate_intensity(input_image, 0.05, 0.95) # 0.01 到 0.99 分位數\n",
    "    normalized_img = ants.iMath_normalize(truncated_img) # 歸一化到 [0, 1] float32\n",
    "    img_uint8 = ((normalized_img - normalized_img.min()) / (normalized_img.max() - normalized_img.min()) * 255).astype('uint8') # Min-Max 歸一化到 [0, 255] unit8\n",
    "    path = os.path.join(output_dir,'ppResult','pp007_result_'+item)\n",
    "    ants.image_write(img_uint8, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa1a03db-4b6b-4495-bdb6-bffcd53aeead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\brainModel\\raw_data\\ABIDE\\collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 561/561 [1:40:59<00:00, 10.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\brainModel\\raw_data\\ADNI\\sc\\CN\\collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 562/562 [1:34:45<00:00, 10.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\brainModel\\raw_data\\IXI\\collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 564/564 [1:27:15<00:00,  9.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\brainModel\\raw_data\\camcan\\collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 653/653 [2:03:16<00:00, 11.33s/it]\n"
     ]
    }
   ],
   "source": [
    "template_image = sitk.ReadImage('mni152-s.nii',sitk.sitkFloat32)\n",
    "input_file = os.path.join(directory, item)\n",
    "output_dir = r'C:\\Users\\user\\Desktop\\brainModel\\pp007'\n",
    "input_image = ants.image_read(input_file)\n",
    "preprocessing(template_image,input_image,output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d81939-8c04-4b61-b89b-ef5a27612407",
   "metadata": {},
   "source": [
    "# 腦齡預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37897f4-cc68-4161-b306-ed2af7fd60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a03e2-a0e3-4b45-89ef-0d37d467a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 sfcn 的基本塊\n",
    "class BasicBlock(nn.Module): # Conv -> BN -> MaxPooling -> ReLU\n",
    "    expansion = 1  # 通道擴展倍數\n",
    "\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_planes, out_planes, kernel_size=3, stride=stride,  padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(out_planes)\n",
    "        self.maxpool1 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = torch.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989902f-4a2f-4102-b081-f0b1afd1f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the full network architecture\n",
    "class SFCN(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(SFCN, self).__init__()\n",
    "        \n",
    "        # Initial channel size\n",
    "        self.in_planes = 1\n",
    "        # Block 1 (Input channel: 1 -> Output channel: 32)\n",
    "        self.layer1 = self._make_layer(BasicBlock, 32, num_blocks=1, stride=1)\n",
    "\n",
    "        # Block 2 (Input channel: 32 -> Output channel: 64)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 64, num_blocks=1, stride=1) \n",
    "\n",
    "        # Block 3 (Input channel: 64 -> Output channel: 128)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 128, num_blocks=1, stride=1)\n",
    "\n",
    "        # Block 4 (Input channel: 128 -> Output channel: 256)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 256, num_blocks=1, stride=1)\n",
    "\n",
    "        # Block 5 (Input channel: 256 -> Output channel: 256)\n",
    "        self.layer5 = self._make_layer(BasicBlock, 256, num_blocks=1, stride=1)\n",
    "\n",
    "        # Stage 2 (Conv1*1 -> BN -> Relu)\n",
    "        self.conv1 = nn.Conv3d(256, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        \n",
    "        # Stage 3 (AvgPool -> Dropout -> Conv1*1)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.conv2 = nn.Conv3d(64, 50, kernel_size=1, stride=1, padding=0)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def _make_layer(self, block, out_planes, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_planes, out_planes, stride))\n",
    "        self.in_planes = out_planes * block.expansion\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(self.in_planes, out_planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Stage 1\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        # Stage 2\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        # Stage 3\n",
    "        x = F.adaptive_avg_pool3d(x, output_size=1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.shape[0], 50)\n",
    "        x = self.softmax(x)\n",
    "        # 權重平均\n",
    "        weights = torch.arange(1, 51, dtype=x.dtype, device=x.device).view(1, -1)\n",
    "        x = torch.sum(x * weights, dim=1, keepdim=True)\n",
    "        x = x * 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8005412-608b-4d48-8224-c6cd4f8efa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnns=[None, None, None, None, None]\n",
    "pt_ls = os.listdir(r'models')\n",
    "for i in range(5):\n",
    "    cnns[i] = SFCN(num_classes=1)\n",
    "    path = os.path.join(r'models',pt_ls[i])\n",
    "    cnns[i].load_state_dict(torch.load(path))\n",
    "    cnns[i].eval()\n",
    "    cnns[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c97b8-56d2-4706-b4cf-1589084e811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros((1,128,192,128),dtype=np.uint8)\n",
    "# 讀檔案\n",
    "path = r'ppResult/'\n",
    "# 製作 numpy image\n",
    "data = nib.load(path)\n",
    "image = data.get_fdata()\n",
    "# 製作 torch image\n",
    "image_tensor = torch.from_numpy(image).to(torch.uint8)  # 儲存為 uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d2a72d-24e7-4014-a9f7-16b1227eea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = image_tensor.to(torch.float32) / 255.0\n",
    "inputs = inputs.unsqueeze(0)\n",
    "# 組合評估\n",
    "ensemble_output = 0.0\n",
    "for model_i in range(5):\n",
    "    outputs = cnns[model_i](inputs)\n",
    "    ensemble_output += outputs.item()*0.2\n",
    "print(ensemble_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
